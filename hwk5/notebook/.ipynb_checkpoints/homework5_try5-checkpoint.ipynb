{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    DSCI 552 Homework 5<br>\n",
    "    Name: Yuhui Zou<br>\n",
    "    USC ID: 1812969805\n",
    "<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_number(y_predict,y_true):\n",
    "    y_predict_copy = list(y_predict)\n",
    "    y_true_copy = list(y_true)\n",
    "    #print(y_true_copy)\n",
    "    number_of_match = 0\n",
    "    for i in range(0,len(y_predict_copy)):\n",
    "        if y_predict_copy[i]==y_true_copy[i]:\n",
    "            number_of_match = number_of_match+1\n",
    "    return number_of_match\n",
    "\n",
    "\n",
    "def add_to_triple(label_triple_list,family_value,genus_value,species_value):\n",
    "    result_triple_list = []\n",
    "    \n",
    "    # family\n",
    "    family_dict = label_triple_list[0]\n",
    "    if family_value in family_dict:\n",
    "        previous_value = family_dict.get(family_value)\n",
    "        family_dict.update({family_value: previous_value+1})\n",
    "    else:\n",
    "        family_dict.update({family_value: 1})\n",
    "    result_triple_list.append(family_dict) \n",
    "    \n",
    "    #genus\n",
    "    genus_dict = label_triple_list[1]\n",
    "    if genus_value in genus_dict:\n",
    "        previous_value = genus_dict.get(genus_value)\n",
    "        genus_dict.update({genus_value: previous_value+1})\n",
    "    else:\n",
    "        genus_dict.update({genus_value: 1})\n",
    "    result_triple_list.append(genus_dict) \n",
    "    \n",
    "    #species\n",
    "    species_dict = label_triple_list[2]\n",
    "    if species_value in species_dict:\n",
    "        previous_value = species_dict.get(species_value)\n",
    "        species_dict.update({species_value: previous_value+1})\n",
    "    else:\n",
    "        species_dict.update({species_value: 1})\n",
    "    result_triple_list.append(species_dict) \n",
    "    \n",
    "    return result_triple_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../data/Anuran_Calls_MFCCs/Frogs_MFCCs.csv',\n",
    "                na_values='?',\n",
    "                index_col=None)\n",
    "\n",
    "df_raw = temp.iloc[:,:-1]\n",
    "X = df_raw.iloc[:,:-3]\n",
    "Y = df_raw.iloc[:,-3:]\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "Y_train_family = Y_train[['Family']]\n",
    "Y_train_genus = Y_train[['Genus']]\n",
    "Y_train_species = Y_train[['Species']]\n",
    "Y_test_family = Y_test[['Family']]\n",
    "Y_test_genus = Y_test[['Genus']]\n",
    "Y_test_species = Y_test[['Species']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ii)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_list = np.linspace(0.1,2,20)\n",
    "temp_list = list(range(-3,6))\n",
    "c_list = []\n",
    "for i in temp_list:\n",
    "    c_list.append(pow(10,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family\n",
    "parameters = {'kernel':['rbf'], 'C':c_list,'gamma':gaussian_list}\n",
    "svc = svm.SVC()\n",
    "clf_family = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "parameters = {'kernel':['rbf'], 'C':c_list,'gamma':gaussian_list}\n",
    "svc = svm.SVC()\n",
    "clf_genus = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "parameters = {'kernel':['rbf'], 'C':c_list,'gamma':gaussian_list}\n",
    "svc = svm.SVC()\n",
    "clf_species = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 6423\n",
      "The hamming score is 0.9916628068550255\n",
      "The hamming loss is 0.008337193144974525\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)*3\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_family['Family'])\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_genus['Genus'])\n",
    "species_match = get_match_number(Y_predict_species,Y_test_species['Species'])\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>iii)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "data = scaler.transform(X_train)\n",
    "standard_X_train = pd.DataFrame(data = scaler.transform(X_train))\n",
    "standard_X_test = pd.DataFrame(data =scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family \n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_family = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_family.fit(standard_X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_genus = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_genus.fit(standard_X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_species = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_species.fit(standard_X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 6139\n",
      "The hamming score is 0.9478153466110854\n",
      "The hamming loss is 0.05218465338891462\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)*3\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_family['Family'])\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_genus['Genus'])\n",
    "species_match = get_match_number(Y_predict_species,Y_test_species['Species'])\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ivï¼‰<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "#X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n",
    "X_train_smote1, Y_train_smote_family = sm.fit_sample(X_train, Y_train_family)\n",
    "X_train_smote2, Y_train_smote_genus = sm.fit_sample(X_train, Y_train_genus)\n",
    "X_train_smote3, Y_train_smote_species = sm.fit_sample(X_train, Y_train_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family  \n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_family = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_family.fit(X_train_smote1, Y_train_smote_family)\n",
    "Y_predict_famlily = clf_family.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_genus = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_genus.fit(X_train_smote2, Y_train_smote_genus)\n",
    "Y_predict_genus = clf_genus.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "parameters = {'penalty':['l1'],'C':c_list,'dual':[False]}\n",
    "svc = LinearSVC()\n",
    "clf_species = GridSearchCV(estimator = svc, param_grid = parameters,cv=10,scoring='accuracy',n_jobs=-1)\n",
    "clf_species.fit(X_train_smote3, Y_train_smote_species)\n",
    "Y_predict_species = clf_species.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 4580\n",
      "The hamming score is 0.7071174926663579\n",
      "The hamming loss is 0.29288250733364213\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)*3\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_family['Family'])\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_genus['Genus'])\n",
    "species_match = get_match_number(Y_predict_species,Y_test_species['Species'])\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 2<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = Y['Family'].tolist()\n",
    "genus_list = Y['Genus'].tolist()\n",
    "species_list = Y['Species'].tolist()\n",
    "hamming_distance_list = []\n",
    "hamming_score_list = []\n",
    "hamming_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_mc in range(0,50):\n",
    "\n",
    "    # find best k for k means clustering\n",
    "    score_list = []\n",
    "    bs = 5\n",
    "    for i in range(2,51):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=i,batch_size=bs).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        score_list.append(metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "\n",
    "    best_k = score_list.index(max(score_list))+2\n",
    "    kmeans = MiniBatchKMeans(n_clusters=best_k,batch_size=bs).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # count majority vote for each cluster\n",
    "    total_list = []\n",
    "    for i in range(0,best_k):\n",
    "        total_list.append([{},{},{}])\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_value = family_list[i]\n",
    "        genus_value = genus_list[i]\n",
    "        species_value = species_list[i]\n",
    "        label_triple = total_list[each_label]\n",
    "        added_triple = add_to_triple(label_triple,family_value,genus_value,species_value)\n",
    "        total_list[each_label]=added_triple\n",
    "\n",
    "    result_label_list = []\n",
    "    for i in range(0,best_k):\n",
    "        result_label_list.append([])\n",
    "\n",
    "    for i in range(0,best_k):\n",
    "        for j in range(0,3):\n",
    "            each_triple = total_list[i][j]\n",
    "            max_key = max(each_triple, key=each_triple.get)\n",
    "            result_label_list[i].append(max_key)\n",
    "\n",
    "    # assign each row with predicted result\n",
    "    family_p_list = []\n",
    "    genus_p_list = []\n",
    "    species_p_list = []\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_p_list.append(result_label_list[each_label][0])\n",
    "        genus_p_list.append(result_label_list[each_label][1])\n",
    "        species_p_list.append(result_label_list[each_label][2])\n",
    "\n",
    "    # calculate hamming \n",
    "    number_of_test = len(family_p_list)*3\n",
    "    family_match = get_match_number(family_p_list,Y['Family'])\n",
    "    genus_match = get_match_number(genus_p_list,Y['Genus'])\n",
    "    species_match = get_match_number(species_p_list,Y['Species'])\n",
    "    total_match = family_match+genus_match+species_match\n",
    "    hamming_distance = number_of_test-total_match\n",
    "    hamming_score = total_match/number_of_test\n",
    "    hamming_loss=hamming_distance/number_of_test\n",
    "    hamming_distance_list.append(hamming_distance)\n",
    "    hamming_score_list.append(hamming_score)\n",
    "    hamming_loss_list.append(hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the list of hamming distance for 50 iterations: [5500, 5361, 4616, 5220, 5180, 6320, 3553, 5093, 3723, 4715, 5623, 4707, 5484, 4825, 6424, 4290, 5497, 6372, 4694, 4922, 5982, 5186, 5397, 5465, 4309, 5275, 5462, 6428, 6096, 4769, 4685, 5791, 5251, 6098, 4330, 6083, 4295, 5242, 5503, 6408, 6449, 5761, 5442, 4342, 5118, 4803, 6119, 5661, 4275, 5677]\n",
      "This is the list of hamming score for 50 iterations: [0.7451934213574242, 0.7516330785267546, 0.7861477878156127, 0.7581653926337735, 0.7600185313875376, 0.7072040769052583, 0.835394950196896, 0.7640491081769748, 0.8275191104933982, 0.7815612694000463, 0.7394950196895993, 0.7819318971507991, 0.7459346768589298, 0.7764651378271948, 0.7023859161454714, 0.8012508686587908, 0.7453324067639564, 0.7047949965253648, 0.7825341672457725, 0.7719712763493166, 0.7228630993745657, 0.759740560574473, 0.749965253648367, 0.7468149177669678, 0.8003706277507528, 0.7556173268473477, 0.7469539031735001, 0.702200602270095, 0.7175816539263378, 0.7790595320824647, 0.7829511234653694, 0.7317118369237897, 0.7567292100996063, 0.7174889969886495, 0.7993977299050267, 0.7181839240213111, 0.8010192263145703, 0.7571461663192032, 0.7450544359508918, 0.703127171646977, 0.7012277044243688, 0.7331016909891128, 0.7478804725503823, 0.7988417882788974, 0.7628908964558722, 0.7774843641417651, 0.7165160991429234, 0.7377345378735233, 0.8019457956914524, 0.7369932823720176]\n",
      "This is the list of hamming loss for 50 iterations: [0.2548065786425759, 0.24836692147324532, 0.2138522121843873, 0.24183460736622656, 0.23998146861246236, 0.29279592309474173, 0.164605049803104, 0.23595089182302525, 0.17248088950660181, 0.21843873059995367, 0.26050498031040076, 0.21806810284920083, 0.25406532314107017, 0.2235348621728052, 0.2976140838545286, 0.19874913134120917, 0.25466759323604354, 0.2952050034746352, 0.21746583275422748, 0.22802872365068336, 0.27713690062543433, 0.240259439425527, 0.2500347463516331, 0.2531850822330322, 0.19962937224924715, 0.2443826731526523, 0.25304609682649987, 0.29779939772990505, 0.2824183460736623, 0.22094046791753533, 0.21704887653463054, 0.26828816307621034, 0.2432707899003938, 0.28251100301135046, 0.20060227009497336, 0.2818160759786889, 0.19898077368542968, 0.24285383368079685, 0.2549455640491082, 0.2968728283530229, 0.29877229557563123, 0.2668983090108872, 0.2521195274496178, 0.20115821172110263, 0.23710910354412787, 0.2225156358582349, 0.2834839008570767, 0.2622654621264767, 0.19805420430854762, 0.2630067176279824]\n"
     ]
    }
   ],
   "source": [
    "print('This is the list of hamming distance for 50 iterations: '+str(hamming_distance_list))\n",
    "print('This is the list of hamming score for 50 iterations: '+str(hamming_score_list))\n",
    "print('This is the list of hamming loss for 50 iterations: '+str(hamming_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of hamming distance = 5276.42\n",
      "The standard deviation of hamming distance = 717.1761593918192\n",
      "The mean of hamming distance = 0.7555515404215891\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n",
      "The mean of hamming distance = 0.24444845957841094\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "hd_mean = statistics.mean(hamming_distance_list)\n",
    "hd_std = statistics.pstdev(hamming_distance_list) \n",
    "print('The mean of hamming distance = '+str(hd_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hd_std))\n",
    "\n",
    "hs_mean = statistics.mean(hamming_score_list)\n",
    "hs_std = statistics.pstdev(hamming_score_list) \n",
    "print('The mean of hamming distance = '+str(hs_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hs_std))\n",
    "\n",
    "hl_mean = statistics.mean(hamming_loss_list)\n",
    "hl_std = statistics.pstdev(hamming_loss_list) \n",
    "print('The mean of hamming distance = '+str(hl_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hl_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ISLR 10.7.2<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can check the notebook folder if the picture did not show successfully.\n"
     ]
    }
   ],
   "source": [
    "print('You can check the notebook folder if the picture did not show successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(a)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(c)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(d)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(e)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_e.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
