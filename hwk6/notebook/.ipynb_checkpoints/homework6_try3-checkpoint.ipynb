{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    DSCI 552 Homework 6<br>\n",
    "    Name: Yuhui Zou<br>\n",
    "    USC ID: 1812969805\n",
    "<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "import math\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(s):\n",
    "    if s=='B':\n",
    "        return 0;\n",
    "    elif s=='M':\n",
    "        return 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.14740</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.06879</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2      3       4       5        6        7        8        9      10  \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "563  20.92  25.09  143.00  1347.0  0.10990  0.22360  0.31740  0.14740  0.2149   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "\n",
       "          11  ...     23      24      25      26      27      28      29  \\\n",
       "0    0.07871  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1    0.05667  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2    0.05999  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3    0.09744  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4    0.05883  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "..       ...  ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "563  0.06879  ...  29.41  179.10  1819.0  0.1407  0.4186  0.6599  0.2542   \n",
       "564  0.05623  ...  26.40  166.10  2027.0  0.1410  0.2113  0.4107  0.2216   \n",
       "565  0.05533  ...  38.25  155.00  1731.0  0.1166  0.1922  0.3215  0.1628   \n",
       "566  0.05648  ...  34.12  126.70  1124.0  0.1139  0.3094  0.3403  0.1418   \n",
       "567  0.07016  ...  39.42  184.60  1821.0  0.1650  0.8681  0.9387  0.2650   \n",
       "\n",
       "         30       31  label  \n",
       "0    0.4601  0.11890      1  \n",
       "1    0.2750  0.08902      1  \n",
       "2    0.3613  0.08758      1  \n",
       "3    0.6638  0.17300      1  \n",
       "4    0.2364  0.07678      1  \n",
       "..      ...      ...    ...  \n",
       "563  0.2929  0.09873      1  \n",
       "564  0.2060  0.07115      1  \n",
       "565  0.2572  0.06637      1  \n",
       "566  0.2218  0.07820      1  \n",
       "567  0.4087  0.12400      1  \n",
       "\n",
       "[212 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('../data/wdbc.csv',\n",
    "                na_values='?',\n",
    "                header=None,\n",
    "                index_col=None)\n",
    "df = temp.iloc[:,1:]\n",
    "df['label'] = df.iloc[:, 0].apply(convert_label)\n",
    "df = df.iloc[:,1:]\n",
    "df_X = df.iloc[:,:-1]\n",
    "df_Y = df.iloc[:,-1:]\n",
    "df_B = df[df.iloc[:, -1] == 0]\n",
    "df_M = df[df.iloc[:, -1] == 1]\n",
    "df_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>i)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(range(-3,6))\n",
    "c_list = []\n",
    "for i in temp_list:\n",
    "    c_list.append(pow(10,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "37       0\n",
       "46       0\n",
       "..     ...\n",
       "558      0\n",
       "559      0\n",
       "560      0\n",
       "561      0\n",
       "568      0\n",
       "\n",
       "[357 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B_X = df_B.iloc[:,:-1]\n",
    "df_B_Y = df_B.iloc[:,-1:]\n",
    "df_M_X = df_M.iloc[:,:-1]\n",
    "df_M_Y = df_M.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_test = []\n",
    "precision_list_test = []\n",
    "recall_list_test = []\n",
    "F1_score_list_test = []\n",
    "auc_list_test = []\n",
    "accuracy_list_train = []\n",
    "precision_list_train = []\n",
    "recall_list_train = []\n",
    "F1_score_list_train = []\n",
    "auc_list_train = []\n",
    "\n",
    "for M in range(0,30):\n",
    "    rs = M\n",
    "    X_B_train, X_B_test, Y_B_train, Y_B_test = model_selection.train_test_split(df_B_X, df_B_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "    X_M_train, X_M_test, Y_M_train, Y_M_test = model_selection.train_test_split(df_M_X, df_M_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "    #X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "    X_train = pd.concat([X_B_train,X_M_train])\n",
    "    X_test = pd.concat([X_B_test,X_M_test])\n",
    "    Y_train = pd.concat([Y_B_train,Y_M_train])\n",
    "    Y_test = pd.concat([Y_B_test,Y_M_test])\n",
    "    \n",
    "    param_grid = {\n",
    "        'svc__penalty':['l1'],\n",
    "        'svc__C':c_list,\n",
    "        'svc__dual':[False]\n",
    "    }\n",
    "    pipe = Pipeline(steps=[('scaler',preprocessing.MinMaxScaler()),('svc', LinearSVC())])\n",
    "    clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    " \n",
    "    # Train\n",
    "    Y_predict_train = clf.predict(X_train)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = Y_train, y_pred = Y_predict_train).ravel()\n",
    "    accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true = Y_train,y_score=Y_predict_train,pos_label=1)\n",
    "    area_under_curve = auc(fpr, tpr)\n",
    "    accuracy_list_train.append(accuracy)\n",
    "    precision_list_train.append(precision)\n",
    "    recall_list_train.append(recall)\n",
    "    F1_score_list_train.append(f1_score)\n",
    "    auc_list_train.append(area_under_curve)\n",
    "\n",
    "    # Test\n",
    "    Y_predict_test = clf.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = Y_test, y_pred = Y_predict_test).ravel()\n",
    "    accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true = Y_test,y_score=Y_predict_test,pos_label=1)\n",
    "    area_under_curve = auc(fpr, tpr)\n",
    "    accuracy_list_test.append(accuracy)\n",
    "    precision_list_test.append(precision)\n",
    "    recall_list_test.append(recall)\n",
    "    F1_score_list_test.append(f1_score)\n",
    "    auc_list_test.append(area_under_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of Monte-Carlo Simulation with M=30 are shown below:\n",
      "\n",
      "For Training:\n",
      "accuracy = 0.9852422907488987\n",
      "precision = 0.9915253338374903\n",
      "recall = 0.9686390532544379\n",
      "F1_score = 0.9799237690245226\n",
      "AUC = 0.9818633862763417\n",
      "\n",
      "For Testing:\n",
      "accuracy = 0.9698550724637681\n",
      "precision = 0.976584717880804\n",
      "recall = 0.9426356589147287\n",
      "F1_score = 0.9587012813647049\n",
      "AUC = 0.9643733850129199\n",
      "\n",
      "\n",
      "For one of the runs:\n",
      "\n",
      "For Training:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[284   1]\n",
      " [  5 164]]\n",
      "\n",
      "\n",
      "For Testing:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[70  2]\n",
      " [ 3 40]]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print('The average of Monte-Carlo Simulation with M=30 are shown below:')\n",
    "print('\\nFor Training:')\n",
    "print('accuracy = '+str(statistics.mean(accuracy_list_train)))\n",
    "print('precision = '+str(statistics.mean(precision_list_train)))\n",
    "print('recall = '+str(statistics.mean(recall_list_train)))\n",
    "print('F1_score = '+str(statistics.mean(F1_score_list_train)))\n",
    "print('AUC = '+str(statistics.mean(auc_list_train)))\n",
    "\n",
    "print('\\nFor Testing:')\n",
    "print('accuracy = '+str(statistics.mean(accuracy_list_test)))\n",
    "print('precision = '+str(statistics.mean(precision_list_test)))\n",
    "print('recall = '+str(statistics.mean(recall_list_test)))\n",
    "print('F1_score = '+str(statistics.mean(F1_score_list_test)))\n",
    "print('AUC = '+str(statistics.mean(auc_list_test)))\n",
    "\n",
    "\n",
    "print('\\n\\nFor one of the runs:')\n",
    "\n",
    "# Training\n",
    "print('\\nFor Training:')\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_train,y_score=Y_predict_train,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Training ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_train, y_pred = Y_predict_train)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)\n",
    "\n",
    "\n",
    "# Testing\n",
    "print('\\n\\nFor Testing:')\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_test,y_score=Y_predict_test,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Testing ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_test, y_pred = Y_predict_test)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ii)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------A-------------------\n",
    "test_B_size = round(df_B.iloc[:,0].size*0.2)\n",
    "test_M_size = round(df_M.iloc[:,0].size*0.2)\n",
    "\n",
    "test_B = df_B.head(test_B_size)\n",
    "test_M = df_M.head(test_M_size)\n",
    "train_B = df_B.iloc[test_B_size:]\n",
    "train_M = df_M.iloc[test_M_size:]\n",
    "test_df = pd.concat([test_B,test_M])\n",
    "\n",
    "train_B_X = train_B.iloc[:,1:]\n",
    "train_B_Y = train_B.iloc[:,:1]\n",
    "train_M_X = train_M.iloc[:,1:]\n",
    "train_M_Y = train_M.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "rs=10\n",
    "label_B_X, unlabel_B_X, label_B_Y, unlabel_B_Y = model_selection.train_test_split(train_B_X, train_B_Y, train_size=0.5,test_size=0.5, random_state=rs);\n",
    "label_M_X, unlabel_M_X, label_M_Y, unlabel_M_Y = model_selection.train_test_split(train_M_X, train_M_Y, train_size=0.5,test_size=0.5, random_state=rs);\n",
    "label_X = pd.concat([label_B_X,label_M_X])\n",
    "unlabel_X = pd.concat([unlabel_B_X,unlabel_M_X])\n",
    "label_Y = pd.concat([label_B_Y,label_M_Y])\n",
    "unlabel_Y = pd.concat([unlabel_B_Y,unlabel_M_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best C by CV\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('svc', LinearSVC())])\n",
    "clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "clf.fit(label_X, label_Y)\n",
    "best_C = clf.best_params_.get('svc__C')\n",
    "best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit label data using linearsvc\n",
    "lsvc = LinearSVC(penalty='l1',C=best_C,dual=False)\n",
    "lsvc.fit(label_X,label_Y)\n",
    "y = lsvc.decision_function(unlabel_X)\n",
    "w_norm = np.linalg.norm(lsvc.coef_)\n",
    "distance_list = y / w_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw_distance = list(abs(clf.decision_function(unlabel_X)))\n",
    "adding_list = sorted(range(len(distance_list)), key=lambda k: distance_list[k],reverse=True)\n",
    "raw_distance[adding_list[0]]\n",
    "adding_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-b72738037097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlabel_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcurrent_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlabel_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m199\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlsvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#lsvc.fit(pd.DataFrame(unlabel_X.iloc[199,:]).transpose(), unlabel_Y.iloc[199,:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#clf.fit(pd.DataFrame(unlabel_X.iloc[199,:]).transpose(), unlabel_Y.iloc[199,:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "unlabel_Y.iloc[199,:]\n",
    "unlabel_X.iloc[199,:]\n",
    "type(unlabel_Y.iloc[199,:])\n",
    "current_data = pd.DataFrame(unlabel_X.iloc[199,:]).transpose()\n",
    "lsvc.predict(current_data)\n",
    "#lsvc.fit(pd.DataFrame(unlabel_X.iloc[199,:]).transpose(), unlabel_Y.iloc[199,:])\n",
    "#clf.fit(pd.DataFrame(unlabel_X.iloc[199,:]).transpose(), unlabel_Y.iloc[199,:])\n",
    "#pd.DataFrame(unlabel_X.iloc[199,:]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>iv）<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote1, Y_test_smote_family = sm.fit_sample(X_test, Y_test['Family'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote2, Y_test_smote_genus = sm.fit_sample(X_test, Y_test['Genus'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote3, Y_test_smote_species = sm.fit_sample(X_test, Y_test['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_family = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(X_test_smote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_genus = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(X_test_smote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_species = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(X_test_smote3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 24273\n",
      "The hamming score is 0.9495735857914092\n",
      "The hamming loss is 0.050426414208590876\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)+len(Y_predict_genus)+len(Y_predict_species)\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_smote_family)\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_smote_genus)\n",
    "species_match = get_match_number(Y_predict_species,Y_test_smote_species)\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the above result we can see that the SVM with gaussian kernel perform best on prediction.\n",
      "And L1 penalized SVM perform worst.\n"
     ]
    }
   ],
   "source": [
    "print('From the above result we can see that the SVM with gaussian kernel perform best on prediction.')\n",
    "print('And L1 penalized SVM perform worst.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 2<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = Y['Family'].tolist()\n",
    "genus_list = Y['Genus'].tolist()\n",
    "species_list = Y['Species'].tolist()\n",
    "hamming_distance_list = []\n",
    "hamming_score_list = []\n",
    "hamming_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_mc in range(0,50):\n",
    "\n",
    "    # find best k for k means clustering\n",
    "    score_list = []\n",
    "    bs = 5\n",
    "    for i in range(2,51):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=i,batch_size=bs).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        score_list.append(metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "\n",
    "    best_k = score_list.index(max(score_list))+2\n",
    "    kmeans = MiniBatchKMeans(n_clusters=best_k,batch_size=bs).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # count majority vote for each cluster\n",
    "    total_list = []\n",
    "    for i in range(0,best_k):\n",
    "        total_list.append([{},{},{}])\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_value = family_list[i]\n",
    "        genus_value = genus_list[i]\n",
    "        species_value = species_list[i]\n",
    "        label_triple = total_list[each_label]\n",
    "        added_triple = add_to_triple(label_triple,family_value,genus_value,species_value)\n",
    "        total_list[each_label]=added_triple\n",
    "\n",
    "    result_label_list = []\n",
    "    for i in range(0,best_k):\n",
    "        result_label_list.append([])\n",
    "\n",
    "    for i in range(0,best_k):\n",
    "        for j in range(0,3):\n",
    "            each_triple = total_list[i][j]\n",
    "            max_key = max(each_triple, key=each_triple.get)\n",
    "            result_label_list[i].append(max_key)\n",
    "\n",
    "    # assign each row with predicted result\n",
    "    family_p_list = []\n",
    "    genus_p_list = []\n",
    "    species_p_list = []\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_p_list.append(result_label_list[each_label][0])\n",
    "        genus_p_list.append(result_label_list[each_label][1])\n",
    "        species_p_list.append(result_label_list[each_label][2])\n",
    "\n",
    "    # calculate hamming \n",
    "    number_of_test = len(family_p_list)*3\n",
    "    family_match = get_match_number(family_p_list,Y['Family'])\n",
    "    genus_match = get_match_number(genus_p_list,Y['Genus'])\n",
    "    species_match = get_match_number(species_p_list,Y['Species'])\n",
    "    total_match = family_match+genus_match+species_match\n",
    "    hamming_distance = number_of_test-total_match\n",
    "    hamming_score = total_match/number_of_test\n",
    "    hamming_loss=hamming_distance/number_of_test\n",
    "    hamming_distance_list.append(hamming_distance)\n",
    "    hamming_score_list.append(hamming_score)\n",
    "    hamming_loss_list.append(hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the list of hamming distance for 50 iterations: [5500, 5361, 4616, 5220, 5180, 6320, 3553, 5093, 3723, 4715, 5623, 4707, 5484, 4825, 6424, 4290, 5497, 6372, 4694, 4922, 5982, 5186, 5397, 5465, 4309, 5275, 5462, 6428, 6096, 4769, 4685, 5791, 5251, 6098, 4330, 6083, 4295, 5242, 5503, 6408, 6449, 5761, 5442, 4342, 5118, 4803, 6119, 5661, 4275, 5677]\n",
      "This is the list of hamming score for 50 iterations: [0.7451934213574242, 0.7516330785267546, 0.7861477878156127, 0.7581653926337735, 0.7600185313875376, 0.7072040769052583, 0.835394950196896, 0.7640491081769748, 0.8275191104933982, 0.7815612694000463, 0.7394950196895993, 0.7819318971507991, 0.7459346768589298, 0.7764651378271948, 0.7023859161454714, 0.8012508686587908, 0.7453324067639564, 0.7047949965253648, 0.7825341672457725, 0.7719712763493166, 0.7228630993745657, 0.759740560574473, 0.749965253648367, 0.7468149177669678, 0.8003706277507528, 0.7556173268473477, 0.7469539031735001, 0.702200602270095, 0.7175816539263378, 0.7790595320824647, 0.7829511234653694, 0.7317118369237897, 0.7567292100996063, 0.7174889969886495, 0.7993977299050267, 0.7181839240213111, 0.8010192263145703, 0.7571461663192032, 0.7450544359508918, 0.703127171646977, 0.7012277044243688, 0.7331016909891128, 0.7478804725503823, 0.7988417882788974, 0.7628908964558722, 0.7774843641417651, 0.7165160991429234, 0.7377345378735233, 0.8019457956914524, 0.7369932823720176]\n",
      "This is the list of hamming loss for 50 iterations: [0.2548065786425759, 0.24836692147324532, 0.2138522121843873, 0.24183460736622656, 0.23998146861246236, 0.29279592309474173, 0.164605049803104, 0.23595089182302525, 0.17248088950660181, 0.21843873059995367, 0.26050498031040076, 0.21806810284920083, 0.25406532314107017, 0.2235348621728052, 0.2976140838545286, 0.19874913134120917, 0.25466759323604354, 0.2952050034746352, 0.21746583275422748, 0.22802872365068336, 0.27713690062543433, 0.240259439425527, 0.2500347463516331, 0.2531850822330322, 0.19962937224924715, 0.2443826731526523, 0.25304609682649987, 0.29779939772990505, 0.2824183460736623, 0.22094046791753533, 0.21704887653463054, 0.26828816307621034, 0.2432707899003938, 0.28251100301135046, 0.20060227009497336, 0.2818160759786889, 0.19898077368542968, 0.24285383368079685, 0.2549455640491082, 0.2968728283530229, 0.29877229557563123, 0.2668983090108872, 0.2521195274496178, 0.20115821172110263, 0.23710910354412787, 0.2225156358582349, 0.2834839008570767, 0.2622654621264767, 0.19805420430854762, 0.2630067176279824]\n"
     ]
    }
   ],
   "source": [
    "print('This is the list of hamming distance for 50 iterations: '+str(hamming_distance_list))\n",
    "print('This is the list of hamming score for 50 iterations: '+str(hamming_score_list))\n",
    "print('This is the list of hamming loss for 50 iterations: '+str(hamming_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of hamming distance = 5276.42\n",
      "The standard deviation of hamming distance = 717.1761593918192\n",
      "The mean of hamming distance = 0.7555515404215891\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n",
      "The mean of hamming distance = 0.24444845957841094\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "hd_mean = statistics.mean(hamming_distance_list)\n",
    "hd_std = statistics.pstdev(hamming_distance_list) \n",
    "print('The mean of hamming distance = '+str(hd_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hd_std))\n",
    "\n",
    "hs_mean = statistics.mean(hamming_score_list)\n",
    "hs_std = statistics.pstdev(hamming_score_list) \n",
    "print('The mean of hamming distance = '+str(hs_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hs_std))\n",
    "\n",
    "hl_mean = statistics.mean(hamming_loss_list)\n",
    "hl_std = statistics.pstdev(hamming_loss_list) \n",
    "print('The mean of hamming distance = '+str(hl_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hl_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ISLR 10.7.2<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can check the notebook folder if the picture did not show successfully.\n"
     ]
    }
   ],
   "source": [
    "print('You can check the notebook folder if the picture did not show successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(a)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(c)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(d)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(e)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_e.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
