{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    DSCI 552 Homework 6<br>\n",
    "    Name: Yuhui Zou<br>\n",
    "    USC ID: 1812969805\n",
    "<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "import math\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(s):\n",
    "    if s=='B':\n",
    "        return 0;\n",
    "    elif s=='M':\n",
    "        return 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.301776</td>\n",
       "      <td>0.179343</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>0.189896</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255425</td>\n",
       "      <td>0.192964</td>\n",
       "      <td>0.245480</td>\n",
       "      <td>0.129276</td>\n",
       "      <td>0.480948</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.442612</td>\n",
       "      <td>0.278336</td>\n",
       "      <td>0.115112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.288655</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.495351</td>\n",
       "      <td>0.330102</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>0.458081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233725</td>\n",
       "      <td>0.225746</td>\n",
       "      <td>0.227501</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>0.242852</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.319141</td>\n",
       "      <td>0.175718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.114367</td>\n",
       "      <td>0.055313</td>\n",
       "      <td>0.449309</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.103181</td>\n",
       "      <td>0.381313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.073310</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.404345</td>\n",
       "      <td>0.084903</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>0.174453</td>\n",
       "      <td>0.148826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286289</td>\n",
       "      <td>0.294555</td>\n",
       "      <td>0.268261</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.335831</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.060028</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191035</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>0.088650</td>\n",
       "      <td>0.170640</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>0.172268</td>\n",
       "      <td>0.083185</td>\n",
       "      <td>0.043618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>0.241123</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.122845</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>0.264925</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.386515</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.303568</td>\n",
       "      <td>0.124951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.438620</td>\n",
       "      <td>0.363486</td>\n",
       "      <td>0.217858</td>\n",
       "      <td>0.289790</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>0.241097</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>0.198990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>0.406450</td>\n",
       "      <td>0.276358</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.207555</td>\n",
       "      <td>0.281175</td>\n",
       "      <td>0.292492</td>\n",
       "      <td>0.379725</td>\n",
       "      <td>0.136606</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>0.214350</td>\n",
       "      <td>0.480893</td>\n",
       "      <td>0.212356</td>\n",
       "      <td>0.110286</td>\n",
       "      <td>0.360928</td>\n",
       "      <td>0.253727</td>\n",
       "      <td>0.260544</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.165657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161864</td>\n",
       "      <td>0.670043</td>\n",
       "      <td>0.158723</td>\n",
       "      <td>0.071028</td>\n",
       "      <td>0.387176</td>\n",
       "      <td>0.217724</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>0.331718</td>\n",
       "      <td>0.107826</td>\n",
       "      <td>0.211728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>0.334564</td>\n",
       "      <td>0.589787</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.193807</td>\n",
       "      <td>0.421233</td>\n",
       "      <td>0.285933</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.213917</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262184</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.349534</td>\n",
       "      <td>0.193178</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>0.360137</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>0.199678</td>\n",
       "      <td>0.664863</td>\n",
       "      <td>0.185751</td>\n",
       "      <td>0.102863</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>0.700426</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.141980</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.026302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label         0         1         2         3         4         5  \\\n",
       "19       0  0.310426  0.157254  0.301776  0.179343  0.407692  0.189896   \n",
       "20       0  0.288655  0.202908  0.289130  0.159703  0.495351  0.330102   \n",
       "21       0  0.119409  0.092323  0.114367  0.055313  0.449309  0.139685   \n",
       "37       0  0.286289  0.294555  0.268261  0.161315  0.335831  0.056070   \n",
       "46       0  0.057504  0.241123  0.054730  0.024772  0.301255  0.122845   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "558      0  0.360121  0.438620  0.363486  0.217858  0.289790  0.348506   \n",
       "559      0  0.214350  0.480893  0.212356  0.110286  0.360928  0.253727   \n",
       "560      0  0.334564  0.589787  0.328865  0.193807  0.421233  0.285933   \n",
       "561      0  0.199678  0.664863  0.185751  0.102863  0.197346  0.049690   \n",
       "568      0  0.036869  0.501522  0.028540  0.015907  0.000000  0.074351   \n",
       "\n",
       "            6         7         8  ...        20        21        22  \\\n",
       "19   0.156139  0.237624  0.416667  ...  0.255425  0.192964  0.245480   \n",
       "20   0.107029  0.154573  0.458081  ...  0.233725  0.225746  0.227501   \n",
       "21   0.069260  0.103181  0.381313  ...  0.081821  0.097015  0.073310   \n",
       "37   0.060028  0.145278  0.205556  ...  0.191035  0.287580  0.169580   \n",
       "46   0.037207  0.029409  0.358081  ...  0.036784  0.264925  0.034115   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "558  0.241097  0.185686  0.198990  ...  0.268588  0.406450  0.276358   \n",
       "559  0.260544  0.204026  0.165657  ...  0.161864  0.670043  0.158723   \n",
       "560  0.104545  0.213917  0.240909  ...  0.262184  0.563699  0.247971   \n",
       "561  0.000000  0.000000  0.000000  ...  0.141942  0.700426  0.123413   \n",
       "568  0.000000  0.000000  0.266162  ...  0.054287  0.489072  0.043578   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "19   0.129276  0.480948  0.145540  0.190895  0.442612  0.278336  0.115112  \n",
       "20   0.109443  0.396421  0.242852  0.150958  0.250275  0.319141  0.175718  \n",
       "21   0.031877  0.404345  0.084903  0.070823  0.213986  0.174453  0.148826  \n",
       "37   0.088650  0.170640  0.018337  0.038602  0.172268  0.083185  0.043618  \n",
       "46   0.014009  0.386515  0.105180  0.054952  0.088110  0.303568  0.124951  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "558  0.134757  0.207555  0.281175  0.292492  0.379725  0.136606  0.163977  \n",
       "559  0.071028  0.387176  0.217724  0.289936  0.331718  0.107826  0.211728  \n",
       "560  0.128170  0.349534  0.193178  0.105911  0.360137  0.135029  0.184770  \n",
       "561  0.062525  0.141980  0.026826  0.000000  0.000000  0.000197  0.026302  \n",
       "568  0.020497  0.124084  0.036043  0.000000  0.000000  0.257441  0.100682  \n",
       "\n",
       "[357 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('../data/wdbc.csv',\n",
    "                na_values='?',\n",
    "                header=None,\n",
    "                index_col=None)\n",
    "df = temp.iloc[:,1:]\n",
    "df['label'] = df.iloc[:, 0].apply(convert_label)\n",
    "df = df.iloc[:,1:]\n",
    "df_X = df.iloc[:,:-1]\n",
    "df_Y = df.iloc[:,-1:]\n",
    "\n",
    "x = df_X.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_X_normalize = pd.DataFrame(x_scaled)\n",
    "df_normalize = pd.concat([df_Y, df_X_normalize], axis=1)\n",
    "df_B = df_normalize[df_normalize.iloc[:, 0] == 0]\n",
    "df_M = df_normalize[df_normalize.iloc[:, 0] == 1]\n",
    "df_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>i)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(range(-3,6))\n",
    "c_list = []\n",
    "for i in temp_list:\n",
    "    c_list.append(pow(10,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B_X = df_B.iloc[:,1:]\n",
    "df_B_Y = df_B.iloc[:,:1]\n",
    "df_M_X = df_M.iloc[:,1:]\n",
    "df_M_Y = df_M.iloc[:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Once--------------\n",
    "# train\n",
    "rs = 10\n",
    "X_B_train, X_B_test, Y_B_train, Y_B_test = model_selection.train_test_split(df_B_X, df_B_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "X_M_train, X_M_test, Y_M_train, Y_M_test = model_selection.train_test_split(df_M_X, df_M_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "X_train = pd.concat([X_B_train,X_M_train])\n",
    "X_test = pd.concat([X_B_test,X_M_test])\n",
    "Y_train = pd.concat([Y_B_train,Y_M_train])\n",
    "Y_test = pd.concat([Y_B_test,Y_M_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For supervise learning with L1 penalized SVM, the calculations are shown below:\n",
      "Calculation for training:\n",
      "Confusion Matrix:\n",
      "[[283   2]\n",
      " [  7 162]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9801762114537445\n",
      "Precision = 0.9878048780487805\n",
      "Recall = 0.9585798816568047\n",
      "F1-score =0.9729729729729729\n",
      "The area under curve is 0.9757811688985778\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('svc', LinearSVC())])\n",
    "clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predict = clf.predict(X_train)\n",
    "\n",
    "print('For supervise learning with L1 penalized SVM, the calculations are shown below:')\n",
    "print('Calculation for training:')\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_train, y_pred = Y_predict)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = Y_train, y_pred = Y_predict).ravel()\n",
    "accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "#print('True positive rate = '+str(tp/(tp+fn)))\n",
    "#print('True negative rate='+str(tn/(tn+fp)))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_train,y_score=Y_predict,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Training ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy = '+str(accuracy))\n",
    "print('Precision = '+str(precision))\n",
    "print('Recall = '+str(recall))\n",
    "print('F1-score ='+str(f1_score))\n",
    "print('The area under curve is '+str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation for testing:\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 3 40]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9739130434782609\n",
      "Precision = 1.0\n",
      "Recall = 0.9302325581395349\n",
      "F1-score =0.963855421686747\n",
      "The area under curve is 0.9651162790697674\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('svc', LinearSVC())])\n",
    "clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predict = clf.predict(X_test)\n",
    "\n",
    "print('Calculation for testing:')\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_test, y_pred = Y_predict)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = Y_test, y_pred = Y_predict).ravel()\n",
    "accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*((precision*recall)/(precision+recall))\n",
    "#print('True positive rate = '+str(tp/(tp+fn)))\n",
    "#print('True negative rate='+str(tn/(tn+fp)))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_test,y_score=Y_predict,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Training ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy = '+str(accuracy))\n",
    "print('Precision = '+str(precision))\n",
    "print('Recall = '+str(recall))\n",
    "print('F1-score ='+str(f1_score))\n",
    "print('The area under curve is '+str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "F1_score_list = []\n",
    "auc_list = []\n",
    "\n",
    "for M in range(0,30):\n",
    "    rs = M\n",
    "    X_B_train, X_B_test, Y_B_train, Y_B_test = model_selection.train_test_split(df_B_X, df_B_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "    X_M_train, X_M_test, Y_M_train, Y_M_test = model_selection.train_test_split(df_M_X, df_M_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "    #X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "    X_train = pd.concat([X_B_train,X_M_train])\n",
    "    X_test = pd.concat([X_B_test,X_M_test])\n",
    "    Y_train = pd.concat([Y_B_train,Y_M_train])\n",
    "    Y_test = pd.concat([Y_B_test,Y_M_test])\n",
    "    \n",
    "    param_grid = {\n",
    "        'svc__penalty':['l1'],\n",
    "        'svc__C':c_list,\n",
    "        'svc__dual':[False]\n",
    "    }\n",
    "    pipe = Pipeline(steps=[('svc', LinearSVC())])\n",
    "    clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predict = clf.predict(X_test)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = Y_test, y_pred = Y_predict).ravel()\n",
    "    accuracy = (tn+tp)/(tn+fp+fn+tp)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true = Y_test,y_score=Y_predict,pos_label=1)\n",
    "    area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    F1_score_list.append(f1_score)\n",
    "    auc_list.append(area_under_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of Monte-Carlo Simulation with M=30 are shown below:\n",
      "accuracy = 0.9695652173913044\n",
      "precision = 0.9757599853577852\n",
      "recall = 0.9426356589147287\n",
      "F1_score = 0.9583492719272901\n",
      "AUC = 0.9641419035314384\n",
      "\n",
      "\n",
      "For one of the runs:\n",
      "Testing:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [115, 454]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-edc340a52d3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# ROC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing ROC Curve\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m--> 775\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [115, 454]"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print('The average of Monte-Carlo Simulation with M=30 are shown below:')\n",
    "print('accuracy = '+str(statistics.mean(accuracy_list)))\n",
    "print('precision = '+str(statistics.mean(precision_list)))\n",
    "print('recall = '+str(statistics.mean(recall_list)))\n",
    "print('F1_score = '+str(statistics.mean(F1_score_list)))\n",
    "print('AUC = '+str(statistics.mean(auc_list)))\n",
    "\n",
    "\n",
    "print('\\n\\nFor one of the runs:')\n",
    "# ROC curve\n",
    "print('For Testing:')\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_test,y_score=Y_predict,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Testing ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_test, y_pred = Y_predict)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)\n",
    "\n",
    "\n",
    "Y_predict = clf.predict(X_train)\n",
    "print('\\n\\nFor Training:')\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_train,y_score=Y_predict,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Training ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix_training = confusion_matrix(y_true = Y_train, y_pred = Y_predict)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ii)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2a64e05988eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mstandard_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "standard_X_test = pd.DataFrame(data =scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_family = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_genus = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_species = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 4735\n",
      "The hamming score is 0.7310483248417478\n",
      "The hamming loss is 0.2689516751582523\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)*3\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_family['Family'])\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_genus['Genus'])\n",
    "species_match = get_match_number(Y_predict_species,Y_test_species['Species'])\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The number of exact match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ivï¼‰<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote1, Y_test_smote_family = sm.fit_sample(X_test, Y_test['Family'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote2, Y_test_smote_genus = sm.fit_sample(X_test, Y_test['Genus'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote3, Y_test_smote_species = sm.fit_sample(X_test, Y_test['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_family = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(X_test_smote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_genus = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(X_test_smote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_species = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(X_test_smote3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 24273\n",
      "The hamming score is 0.9495735857914092\n",
      "The hamming loss is 0.050426414208590876\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)+len(Y_predict_genus)+len(Y_predict_species)\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_smote_family)\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_smote_genus)\n",
    "species_match = get_match_number(Y_predict_species,Y_test_smote_species)\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the above result we can see that the SVM with gaussian kernel perform best on prediction.\n",
      "And L1 penalized SVM perform worst.\n"
     ]
    }
   ],
   "source": [
    "print('From the above result we can see that the SVM with gaussian kernel perform best on prediction.')\n",
    "print('And L1 penalized SVM perform worst.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 2<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = Y['Family'].tolist()\n",
    "genus_list = Y['Genus'].tolist()\n",
    "species_list = Y['Species'].tolist()\n",
    "hamming_distance_list = []\n",
    "hamming_score_list = []\n",
    "hamming_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_mc in range(0,50):\n",
    "\n",
    "    # find best k for k means clustering\n",
    "    score_list = []\n",
    "    bs = 5\n",
    "    for i in range(2,51):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=i,batch_size=bs).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        score_list.append(metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "\n",
    "    best_k = score_list.index(max(score_list))+2\n",
    "    kmeans = MiniBatchKMeans(n_clusters=best_k,batch_size=bs).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # count majority vote for each cluster\n",
    "    total_list = []\n",
    "    for i in range(0,best_k):\n",
    "        total_list.append([{},{},{}])\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_value = family_list[i]\n",
    "        genus_value = genus_list[i]\n",
    "        species_value = species_list[i]\n",
    "        label_triple = total_list[each_label]\n",
    "        added_triple = add_to_triple(label_triple,family_value,genus_value,species_value)\n",
    "        total_list[each_label]=added_triple\n",
    "\n",
    "    result_label_list = []\n",
    "    for i in range(0,best_k):\n",
    "        result_label_list.append([])\n",
    "\n",
    "    for i in range(0,best_k):\n",
    "        for j in range(0,3):\n",
    "            each_triple = total_list[i][j]\n",
    "            max_key = max(each_triple, key=each_triple.get)\n",
    "            result_label_list[i].append(max_key)\n",
    "\n",
    "    # assign each row with predicted result\n",
    "    family_p_list = []\n",
    "    genus_p_list = []\n",
    "    species_p_list = []\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_p_list.append(result_label_list[each_label][0])\n",
    "        genus_p_list.append(result_label_list[each_label][1])\n",
    "        species_p_list.append(result_label_list[each_label][2])\n",
    "\n",
    "    # calculate hamming \n",
    "    number_of_test = len(family_p_list)*3\n",
    "    family_match = get_match_number(family_p_list,Y['Family'])\n",
    "    genus_match = get_match_number(genus_p_list,Y['Genus'])\n",
    "    species_match = get_match_number(species_p_list,Y['Species'])\n",
    "    total_match = family_match+genus_match+species_match\n",
    "    hamming_distance = number_of_test-total_match\n",
    "    hamming_score = total_match/number_of_test\n",
    "    hamming_loss=hamming_distance/number_of_test\n",
    "    hamming_distance_list.append(hamming_distance)\n",
    "    hamming_score_list.append(hamming_score)\n",
    "    hamming_loss_list.append(hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the list of hamming distance for 50 iterations: [5500, 5361, 4616, 5220, 5180, 6320, 3553, 5093, 3723, 4715, 5623, 4707, 5484, 4825, 6424, 4290, 5497, 6372, 4694, 4922, 5982, 5186, 5397, 5465, 4309, 5275, 5462, 6428, 6096, 4769, 4685, 5791, 5251, 6098, 4330, 6083, 4295, 5242, 5503, 6408, 6449, 5761, 5442, 4342, 5118, 4803, 6119, 5661, 4275, 5677]\n",
      "This is the list of hamming score for 50 iterations: [0.7451934213574242, 0.7516330785267546, 0.7861477878156127, 0.7581653926337735, 0.7600185313875376, 0.7072040769052583, 0.835394950196896, 0.7640491081769748, 0.8275191104933982, 0.7815612694000463, 0.7394950196895993, 0.7819318971507991, 0.7459346768589298, 0.7764651378271948, 0.7023859161454714, 0.8012508686587908, 0.7453324067639564, 0.7047949965253648, 0.7825341672457725, 0.7719712763493166, 0.7228630993745657, 0.759740560574473, 0.749965253648367, 0.7468149177669678, 0.8003706277507528, 0.7556173268473477, 0.7469539031735001, 0.702200602270095, 0.7175816539263378, 0.7790595320824647, 0.7829511234653694, 0.7317118369237897, 0.7567292100996063, 0.7174889969886495, 0.7993977299050267, 0.7181839240213111, 0.8010192263145703, 0.7571461663192032, 0.7450544359508918, 0.703127171646977, 0.7012277044243688, 0.7331016909891128, 0.7478804725503823, 0.7988417882788974, 0.7628908964558722, 0.7774843641417651, 0.7165160991429234, 0.7377345378735233, 0.8019457956914524, 0.7369932823720176]\n",
      "This is the list of hamming loss for 50 iterations: [0.2548065786425759, 0.24836692147324532, 0.2138522121843873, 0.24183460736622656, 0.23998146861246236, 0.29279592309474173, 0.164605049803104, 0.23595089182302525, 0.17248088950660181, 0.21843873059995367, 0.26050498031040076, 0.21806810284920083, 0.25406532314107017, 0.2235348621728052, 0.2976140838545286, 0.19874913134120917, 0.25466759323604354, 0.2952050034746352, 0.21746583275422748, 0.22802872365068336, 0.27713690062543433, 0.240259439425527, 0.2500347463516331, 0.2531850822330322, 0.19962937224924715, 0.2443826731526523, 0.25304609682649987, 0.29779939772990505, 0.2824183460736623, 0.22094046791753533, 0.21704887653463054, 0.26828816307621034, 0.2432707899003938, 0.28251100301135046, 0.20060227009497336, 0.2818160759786889, 0.19898077368542968, 0.24285383368079685, 0.2549455640491082, 0.2968728283530229, 0.29877229557563123, 0.2668983090108872, 0.2521195274496178, 0.20115821172110263, 0.23710910354412787, 0.2225156358582349, 0.2834839008570767, 0.2622654621264767, 0.19805420430854762, 0.2630067176279824]\n"
     ]
    }
   ],
   "source": [
    "print('This is the list of hamming distance for 50 iterations: '+str(hamming_distance_list))\n",
    "print('This is the list of hamming score for 50 iterations: '+str(hamming_score_list))\n",
    "print('This is the list of hamming loss for 50 iterations: '+str(hamming_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of hamming distance = 5276.42\n",
      "The standard deviation of hamming distance = 717.1761593918192\n",
      "The mean of hamming distance = 0.7555515404215891\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n",
      "The mean of hamming distance = 0.24444845957841094\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "hd_mean = statistics.mean(hamming_distance_list)\n",
    "hd_std = statistics.pstdev(hamming_distance_list) \n",
    "print('The mean of hamming distance = '+str(hd_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hd_std))\n",
    "\n",
    "hs_mean = statistics.mean(hamming_score_list)\n",
    "hs_std = statistics.pstdev(hamming_score_list) \n",
    "print('The mean of hamming distance = '+str(hs_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hs_std))\n",
    "\n",
    "hl_mean = statistics.mean(hamming_loss_list)\n",
    "hl_std = statistics.pstdev(hamming_loss_list) \n",
    "print('The mean of hamming distance = '+str(hl_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hl_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ISLR 10.7.2<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can check the notebook folder if the picture did not show successfully.\n"
     ]
    }
   ],
   "source": [
    "print('You can check the notebook folder if the picture did not show successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(a)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(c)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(d)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(e)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_e.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
