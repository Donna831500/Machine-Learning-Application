{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    DSCI 552 Homework 6<br>\n",
    "    Name: Yuhui Zou<br>\n",
    "    USC ID: 1812969805\n",
    "<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "import math\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(s):\n",
    "    if s=='B':\n",
    "        return 0;\n",
    "    elif s=='M':\n",
    "        return 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../data/wdbc.csv',\n",
    "                na_values='?',\n",
    "                header=None,\n",
    "                index_col=None)\n",
    "df = temp.iloc[:,1:]\n",
    "df_X = df.iloc[:,:]\n",
    "\n",
    "\n",
    "#df_normalize = \n",
    "df_B = df[df[1] == 'B']\n",
    "df_M = df[df[1] == 'M']\n",
    "#number_of_B = df_B.iloc[:,0].size\n",
    "#number_of_M = df_M.iloc[:,0].size\n",
    "test_B_size = round(df_B.iloc[:,0].size*0.2)\n",
    "test_M_size = round(df_M.iloc[:,0].size*0.2)\n",
    "\n",
    "test_B = df_B.head(test_B_size)\n",
    "test_M = df_M.head(test_M_size)\n",
    "train_B = df_B.iloc[test_B_size:]\n",
    "train_M = df_M.iloc[test_M_size:]\n",
    "\n",
    "\n",
    "#df_B_X = df_B.iloc[:,1:]\n",
    "#df_B_Y = df_B.iloc[:,:1]\n",
    "#df_M_X = df_M.iloc[:,1:]\n",
    "#df_M_Y = df_M.iloc[:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.301776</td>\n",
       "      <td>0.179343</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>0.189896</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255425</td>\n",
       "      <td>0.192964</td>\n",
       "      <td>0.245480</td>\n",
       "      <td>0.129276</td>\n",
       "      <td>0.480948</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.442612</td>\n",
       "      <td>0.278336</td>\n",
       "      <td>0.115112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.288655</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.495351</td>\n",
       "      <td>0.330102</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>0.458081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233725</td>\n",
       "      <td>0.225746</td>\n",
       "      <td>0.227501</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>0.242852</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.319141</td>\n",
       "      <td>0.175718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.114367</td>\n",
       "      <td>0.055313</td>\n",
       "      <td>0.449309</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.103181</td>\n",
       "      <td>0.381313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.073310</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.404345</td>\n",
       "      <td>0.084903</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>0.174453</td>\n",
       "      <td>0.148826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286289</td>\n",
       "      <td>0.294555</td>\n",
       "      <td>0.268261</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.335831</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.060028</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191035</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>0.088650</td>\n",
       "      <td>0.170640</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>0.172268</td>\n",
       "      <td>0.083185</td>\n",
       "      <td>0.043618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>0.241123</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.122845</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>0.264925</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.386515</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.303568</td>\n",
       "      <td>0.124951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.438620</td>\n",
       "      <td>0.363486</td>\n",
       "      <td>0.217858</td>\n",
       "      <td>0.289790</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>0.241097</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>0.198990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>0.406450</td>\n",
       "      <td>0.276358</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.207555</td>\n",
       "      <td>0.281175</td>\n",
       "      <td>0.292492</td>\n",
       "      <td>0.379725</td>\n",
       "      <td>0.136606</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>0.214350</td>\n",
       "      <td>0.480893</td>\n",
       "      <td>0.212356</td>\n",
       "      <td>0.110286</td>\n",
       "      <td>0.360928</td>\n",
       "      <td>0.253727</td>\n",
       "      <td>0.260544</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.165657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161864</td>\n",
       "      <td>0.670043</td>\n",
       "      <td>0.158723</td>\n",
       "      <td>0.071028</td>\n",
       "      <td>0.387176</td>\n",
       "      <td>0.217724</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>0.331718</td>\n",
       "      <td>0.107826</td>\n",
       "      <td>0.211728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>0.334564</td>\n",
       "      <td>0.589787</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.193807</td>\n",
       "      <td>0.421233</td>\n",
       "      <td>0.285933</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.213917</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262184</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.349534</td>\n",
       "      <td>0.193178</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>0.360137</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>0.199678</td>\n",
       "      <td>0.664863</td>\n",
       "      <td>0.185751</td>\n",
       "      <td>0.102863</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>0.700426</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.141980</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.026302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label         0         1         2         3         4         5  \\\n",
       "19       0  0.310426  0.157254  0.301776  0.179343  0.407692  0.189896   \n",
       "20       0  0.288655  0.202908  0.289130  0.159703  0.495351  0.330102   \n",
       "21       0  0.119409  0.092323  0.114367  0.055313  0.449309  0.139685   \n",
       "37       0  0.286289  0.294555  0.268261  0.161315  0.335831  0.056070   \n",
       "46       0  0.057504  0.241123  0.054730  0.024772  0.301255  0.122845   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "558      0  0.360121  0.438620  0.363486  0.217858  0.289790  0.348506   \n",
       "559      0  0.214350  0.480893  0.212356  0.110286  0.360928  0.253727   \n",
       "560      0  0.334564  0.589787  0.328865  0.193807  0.421233  0.285933   \n",
       "561      0  0.199678  0.664863  0.185751  0.102863  0.197346  0.049690   \n",
       "568      0  0.036869  0.501522  0.028540  0.015907  0.000000  0.074351   \n",
       "\n",
       "            6         7         8  ...        20        21        22  \\\n",
       "19   0.156139  0.237624  0.416667  ...  0.255425  0.192964  0.245480   \n",
       "20   0.107029  0.154573  0.458081  ...  0.233725  0.225746  0.227501   \n",
       "21   0.069260  0.103181  0.381313  ...  0.081821  0.097015  0.073310   \n",
       "37   0.060028  0.145278  0.205556  ...  0.191035  0.287580  0.169580   \n",
       "46   0.037207  0.029409  0.358081  ...  0.036784  0.264925  0.034115   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "558  0.241097  0.185686  0.198990  ...  0.268588  0.406450  0.276358   \n",
       "559  0.260544  0.204026  0.165657  ...  0.161864  0.670043  0.158723   \n",
       "560  0.104545  0.213917  0.240909  ...  0.262184  0.563699  0.247971   \n",
       "561  0.000000  0.000000  0.000000  ...  0.141942  0.700426  0.123413   \n",
       "568  0.000000  0.000000  0.266162  ...  0.054287  0.489072  0.043578   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "19   0.129276  0.480948  0.145540  0.190895  0.442612  0.278336  0.115112  \n",
       "20   0.109443  0.396421  0.242852  0.150958  0.250275  0.319141  0.175718  \n",
       "21   0.031877  0.404345  0.084903  0.070823  0.213986  0.174453  0.148826  \n",
       "37   0.088650  0.170640  0.018337  0.038602  0.172268  0.083185  0.043618  \n",
       "46   0.014009  0.386515  0.105180  0.054952  0.088110  0.303568  0.124951  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "558  0.134757  0.207555  0.281175  0.292492  0.379725  0.136606  0.163977  \n",
       "559  0.071028  0.387176  0.217724  0.289936  0.331718  0.107826  0.211728  \n",
       "560  0.128170  0.349534  0.193178  0.105911  0.360137  0.135029  0.184770  \n",
       "561  0.062525  0.141980  0.026826  0.000000  0.000000  0.000197  0.026302  \n",
       "568  0.020497  0.124084  0.036043  0.000000  0.000000  0.257441  0.100682  \n",
       "\n",
       "[357 rows x 31 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('../data/wdbc.csv',\n",
    "                na_values='?',\n",
    "                header=None,\n",
    "                index_col=None)\n",
    "df = temp.iloc[:,1:]\n",
    "df['label'] = df.iloc[:, 0].apply(convert_label)\n",
    "df = df.iloc[:,1:]\n",
    "df_X = df.iloc[:,:-1]\n",
    "df_Y = df.iloc[:,-1:]\n",
    "\n",
    "x = df_X.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_X_normalize = pd.DataFrame(x_scaled)\n",
    "df_normalize = pd.concat([df_Y, df_X_normalize], axis=1)\n",
    "df_B = df_normalize[df_normalize.iloc[:, 0] == 0]\n",
    "df_M = df_normalize[df_normalize.iloc[:, 0] == 1]\n",
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.301776</td>\n",
       "      <td>0.179343</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>0.189896</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255425</td>\n",
       "      <td>0.192964</td>\n",
       "      <td>0.245480</td>\n",
       "      <td>0.129276</td>\n",
       "      <td>0.480948</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.190895</td>\n",
       "      <td>0.442612</td>\n",
       "      <td>0.278336</td>\n",
       "      <td>0.115112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B</td>\n",
       "      <td>0.288655</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.495351</td>\n",
       "      <td>0.330102</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.154573</td>\n",
       "      <td>0.458081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233725</td>\n",
       "      <td>0.225746</td>\n",
       "      <td>0.227501</td>\n",
       "      <td>0.109443</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>0.242852</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.319141</td>\n",
       "      <td>0.175718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.114367</td>\n",
       "      <td>0.055313</td>\n",
       "      <td>0.449309</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.103181</td>\n",
       "      <td>0.381313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.073310</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.404345</td>\n",
       "      <td>0.084903</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>0.174453</td>\n",
       "      <td>0.148826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B</td>\n",
       "      <td>0.286289</td>\n",
       "      <td>0.294555</td>\n",
       "      <td>0.268261</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.335831</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.060028</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191035</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>0.088650</td>\n",
       "      <td>0.170640</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>0.172268</td>\n",
       "      <td>0.083185</td>\n",
       "      <td>0.043618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>B</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>0.241123</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.122845</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>0.264925</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.386515</td>\n",
       "      <td>0.105180</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.303568</td>\n",
       "      <td>0.124951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>B</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.438620</td>\n",
       "      <td>0.363486</td>\n",
       "      <td>0.217858</td>\n",
       "      <td>0.289790</td>\n",
       "      <td>0.348506</td>\n",
       "      <td>0.241097</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>0.198990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>0.406450</td>\n",
       "      <td>0.276358</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>0.207555</td>\n",
       "      <td>0.281175</td>\n",
       "      <td>0.292492</td>\n",
       "      <td>0.379725</td>\n",
       "      <td>0.136606</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>B</td>\n",
       "      <td>0.214350</td>\n",
       "      <td>0.480893</td>\n",
       "      <td>0.212356</td>\n",
       "      <td>0.110286</td>\n",
       "      <td>0.360928</td>\n",
       "      <td>0.253727</td>\n",
       "      <td>0.260544</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.165657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161864</td>\n",
       "      <td>0.670043</td>\n",
       "      <td>0.158723</td>\n",
       "      <td>0.071028</td>\n",
       "      <td>0.387176</td>\n",
       "      <td>0.217724</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>0.331718</td>\n",
       "      <td>0.107826</td>\n",
       "      <td>0.211728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>B</td>\n",
       "      <td>0.334564</td>\n",
       "      <td>0.589787</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.193807</td>\n",
       "      <td>0.421233</td>\n",
       "      <td>0.285933</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.213917</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262184</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.349534</td>\n",
       "      <td>0.193178</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>0.360137</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>B</td>\n",
       "      <td>0.199678</td>\n",
       "      <td>0.664863</td>\n",
       "      <td>0.185751</td>\n",
       "      <td>0.102863</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>0.700426</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.141980</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.026302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1         0         1         2         3         4         5         6   \\\n",
       "19    B  0.310426  0.157254  0.301776  0.179343  0.407692  0.189896  0.156139   \n",
       "20    B  0.288655  0.202908  0.289130  0.159703  0.495351  0.330102  0.107029   \n",
       "21    B  0.119409  0.092323  0.114367  0.055313  0.449309  0.139685  0.069260   \n",
       "37    B  0.286289  0.294555  0.268261  0.161315  0.335831  0.056070  0.060028   \n",
       "46    B  0.057504  0.241123  0.054730  0.024772  0.301255  0.122845  0.037207   \n",
       "..   ..       ...       ...       ...       ...       ...       ...       ...   \n",
       "558   B  0.360121  0.438620  0.363486  0.217858  0.289790  0.348506  0.241097   \n",
       "559   B  0.214350  0.480893  0.212356  0.110286  0.360928  0.253727  0.260544   \n",
       "560   B  0.334564  0.589787  0.328865  0.193807  0.421233  0.285933  0.104545   \n",
       "561   B  0.199678  0.664863  0.185751  0.102863  0.197346  0.049690  0.000000   \n",
       "568   B  0.036869  0.501522  0.028540  0.015907  0.000000  0.074351  0.000000   \n",
       "\n",
       "           7         8   ...        20        21        22        23  \\\n",
       "19   0.237624  0.416667  ...  0.255425  0.192964  0.245480  0.129276   \n",
       "20   0.154573  0.458081  ...  0.233725  0.225746  0.227501  0.109443   \n",
       "21   0.103181  0.381313  ...  0.081821  0.097015  0.073310  0.031877   \n",
       "37   0.145278  0.205556  ...  0.191035  0.287580  0.169580  0.088650   \n",
       "46   0.029409  0.358081  ...  0.036784  0.264925  0.034115  0.014009   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "558  0.185686  0.198990  ...  0.268588  0.406450  0.276358  0.134757   \n",
       "559  0.204026  0.165657  ...  0.161864  0.670043  0.158723  0.071028   \n",
       "560  0.213917  0.240909  ...  0.262184  0.563699  0.247971  0.128170   \n",
       "561  0.000000  0.000000  ...  0.141942  0.700426  0.123413  0.062525   \n",
       "568  0.000000  0.266162  ...  0.054287  0.489072  0.043578  0.020497   \n",
       "\n",
       "           24        25        26        27        28        29  \n",
       "19   0.480948  0.145540  0.190895  0.442612  0.278336  0.115112  \n",
       "20   0.396421  0.242852  0.150958  0.250275  0.319141  0.175718  \n",
       "21   0.404345  0.084903  0.070823  0.213986  0.174453  0.148826  \n",
       "37   0.170640  0.018337  0.038602  0.172268  0.083185  0.043618  \n",
       "46   0.386515  0.105180  0.054952  0.088110  0.303568  0.124951  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "558  0.207555  0.281175  0.292492  0.379725  0.136606  0.163977  \n",
       "559  0.387176  0.217724  0.289936  0.331718  0.107826  0.211728  \n",
       "560  0.349534  0.193178  0.105911  0.360137  0.135029  0.184770  \n",
       "561  0.141980  0.026826  0.000000  0.000000  0.000197  0.026302  \n",
       "568  0.124084  0.036043  0.000000  0.000000  0.257441  0.100682  \n",
       "\n",
       "[357 rows x 31 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('../data/wdbc.csv',\n",
    "                na_values='?',\n",
    "                header=None,\n",
    "                index_col=None)\n",
    "df = temp.iloc[:,1:]\n",
    "df_X = df.iloc[:,1:]\n",
    "df_Y = df.iloc[:,:1]\n",
    "\n",
    "x = df_X.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_X_normalize = pd.DataFrame(x_scaled)\n",
    "df_normalize = pd.concat([df_Y, df_X_normalize], axis=1)\n",
    "df_B = df_normalize[df_normalize.iloc[:, 0] == 'B']\n",
    "df_M = df_normalize[df_normalize.iloc[:, 0] == 'M']\n",
    "df_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>part (b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>i)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(range(-3,6))\n",
    "c_list = []\n",
    "for i in temp_list:\n",
    "    c_list.append(pow(10,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B_X = df_B.iloc[:,1:]\n",
    "df_B_Y = df_B.iloc[:,:1]\n",
    "df_M_X = df_M.iloc[:,1:]\n",
    "df_M_Y = df_M.iloc[:,:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Once--------------\n",
    "# train\n",
    "rs = 10\n",
    "X_B_train, X_B_test, Y_B_train, Y_B_test = model_selection.train_test_split(df_B_X, df_B_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "X_M_train, X_M_test, Y_M_train, Y_M_test = model_selection.train_test_split(df_M_X, df_M_Y, train_size=0.8,test_size=0.2, random_state=rs);\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=0.7,test_size=0.3, random_state=10);\n",
    "X_train = pd.concat([X_B_train,X_M_train])\n",
    "X_test = pd.concat([X_B_test,X_M_test])\n",
    "Y_train = pd.concat([Y_B_train,Y_M_train])\n",
    "Y_test = pd.concat([Y_B_test,Y_M_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('svc', LinearSVC())])\n",
    "clf = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predict = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-3e8bb4cfa795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# ROC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ROC Curve\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m--> 775\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;31m# the indices associated with the distinct values. We also\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# concatenate a value for the end of the curve.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mdistinct_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m     \u001b[0mthreshold_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistinct_value_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnot_equal\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msubtract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = Y_train, y_pred = Y_predict).ravel()\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true = Y_train,y_score=Y_predict,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>iii)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2a64e05988eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mstandard_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "standard_X_test = pd.DataFrame(data =scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_family = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_genus = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', LinearSVC())])\n",
    "clf_species = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(standard_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 4735\n",
      "The hamming score is 0.7310483248417478\n",
      "The hamming loss is 0.2689516751582523\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)*3\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_family['Family'])\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_genus['Genus'])\n",
    "species_match = get_match_number(Y_predict_species,Y_test_species['Species'])\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The number of exact match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>iv）<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote1, Y_test_smote_family = sm.fit_sample(X_test, Y_test['Family'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote2, Y_test_smote_genus = sm.fit_sample(X_test, Y_test['Genus'])\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_test_smote3, Y_test_smote_species = sm.fit_sample(X_test, Y_test['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_family = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_family.fit(X_train, Y_train_family)\n",
    "Y_predict_famlily = clf_family.predict(X_test_smote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_genus = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_genus.fit(X_train, Y_train_genus)\n",
    "Y_predict_genus = clf_genus.predict(X_test_smote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "param_grid = {\n",
    "    'svc__penalty':['l1'],\n",
    "    'svc__C':c_list,\n",
    "    'svc__dual':[False]\n",
    "}\n",
    "pipe = Pipeline(steps=[('smote', SMOTE(random_state = 2)), ('svc', LinearSVC())])\n",
    "clf_species = GridSearchCV(estimator = pipe, n_jobs=-1, param_grid=param_grid,cv=10,scoring='accuracy')\n",
    "clf_species.fit(X_train, Y_train_species)\n",
    "Y_predict_species = clf_species.predict(X_test_smote3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact number of match is 24273\n",
      "The hamming score is 0.9495735857914092\n",
      "The hamming loss is 0.050426414208590876\n"
     ]
    }
   ],
   "source": [
    "number_of_test = len(Y_predict_famlily)+len(Y_predict_genus)+len(Y_predict_species)\n",
    "family_match = get_match_number(Y_predict_famlily,Y_test_smote_family)\n",
    "genus_match = get_match_number(Y_predict_genus,Y_test_smote_genus)\n",
    "species_match = get_match_number(Y_predict_species,Y_test_smote_species)\n",
    "total_match = family_match+genus_match+species_match\n",
    "hamming_score = total_match/number_of_test\n",
    "hamming_loss=(number_of_test-total_match)/number_of_test\n",
    "print('The exact number of match is '+str(total_match))\n",
    "print('The hamming score is '+str(hamming_score))\n",
    "print('The hamming loss is '+str(hamming_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the above result we can see that the SVM with gaussian kernel perform best on prediction.\n",
      "And L1 penalized SVM perform worst.\n"
     ]
    }
   ],
   "source": [
    "print('From the above result we can see that the SVM with gaussian kernel perform best on prediction.')\n",
    "print('And L1 penalized SVM perform worst.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 2<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = Y['Family'].tolist()\n",
    "genus_list = Y['Genus'].tolist()\n",
    "species_list = Y['Species'].tolist()\n",
    "hamming_distance_list = []\n",
    "hamming_score_list = []\n",
    "hamming_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_mc in range(0,50):\n",
    "\n",
    "    # find best k for k means clustering\n",
    "    score_list = []\n",
    "    bs = 5\n",
    "    for i in range(2,51):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=i,batch_size=bs).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        score_list.append(metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "\n",
    "    best_k = score_list.index(max(score_list))+2\n",
    "    kmeans = MiniBatchKMeans(n_clusters=best_k,batch_size=bs).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # count majority vote for each cluster\n",
    "    total_list = []\n",
    "    for i in range(0,best_k):\n",
    "        total_list.append([{},{},{}])\n",
    "\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_value = family_list[i]\n",
    "        genus_value = genus_list[i]\n",
    "        species_value = species_list[i]\n",
    "        label_triple = total_list[each_label]\n",
    "        added_triple = add_to_triple(label_triple,family_value,genus_value,species_value)\n",
    "        total_list[each_label]=added_triple\n",
    "\n",
    "    result_label_list = []\n",
    "    for i in range(0,best_k):\n",
    "        result_label_list.append([])\n",
    "\n",
    "    for i in range(0,best_k):\n",
    "        for j in range(0,3):\n",
    "            each_triple = total_list[i][j]\n",
    "            max_key = max(each_triple, key=each_triple.get)\n",
    "            result_label_list[i].append(max_key)\n",
    "\n",
    "    # assign each row with predicted result\n",
    "    family_p_list = []\n",
    "    genus_p_list = []\n",
    "    species_p_list = []\n",
    "    for i in range(0,len(labels)):\n",
    "        each_label = labels[i]\n",
    "        family_p_list.append(result_label_list[each_label][0])\n",
    "        genus_p_list.append(result_label_list[each_label][1])\n",
    "        species_p_list.append(result_label_list[each_label][2])\n",
    "\n",
    "    # calculate hamming \n",
    "    number_of_test = len(family_p_list)*3\n",
    "    family_match = get_match_number(family_p_list,Y['Family'])\n",
    "    genus_match = get_match_number(genus_p_list,Y['Genus'])\n",
    "    species_match = get_match_number(species_p_list,Y['Species'])\n",
    "    total_match = family_match+genus_match+species_match\n",
    "    hamming_distance = number_of_test-total_match\n",
    "    hamming_score = total_match/number_of_test\n",
    "    hamming_loss=hamming_distance/number_of_test\n",
    "    hamming_distance_list.append(hamming_distance)\n",
    "    hamming_score_list.append(hamming_score)\n",
    "    hamming_loss_list.append(hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the list of hamming distance for 50 iterations: [5500, 5361, 4616, 5220, 5180, 6320, 3553, 5093, 3723, 4715, 5623, 4707, 5484, 4825, 6424, 4290, 5497, 6372, 4694, 4922, 5982, 5186, 5397, 5465, 4309, 5275, 5462, 6428, 6096, 4769, 4685, 5791, 5251, 6098, 4330, 6083, 4295, 5242, 5503, 6408, 6449, 5761, 5442, 4342, 5118, 4803, 6119, 5661, 4275, 5677]\n",
      "This is the list of hamming score for 50 iterations: [0.7451934213574242, 0.7516330785267546, 0.7861477878156127, 0.7581653926337735, 0.7600185313875376, 0.7072040769052583, 0.835394950196896, 0.7640491081769748, 0.8275191104933982, 0.7815612694000463, 0.7394950196895993, 0.7819318971507991, 0.7459346768589298, 0.7764651378271948, 0.7023859161454714, 0.8012508686587908, 0.7453324067639564, 0.7047949965253648, 0.7825341672457725, 0.7719712763493166, 0.7228630993745657, 0.759740560574473, 0.749965253648367, 0.7468149177669678, 0.8003706277507528, 0.7556173268473477, 0.7469539031735001, 0.702200602270095, 0.7175816539263378, 0.7790595320824647, 0.7829511234653694, 0.7317118369237897, 0.7567292100996063, 0.7174889969886495, 0.7993977299050267, 0.7181839240213111, 0.8010192263145703, 0.7571461663192032, 0.7450544359508918, 0.703127171646977, 0.7012277044243688, 0.7331016909891128, 0.7478804725503823, 0.7988417882788974, 0.7628908964558722, 0.7774843641417651, 0.7165160991429234, 0.7377345378735233, 0.8019457956914524, 0.7369932823720176]\n",
      "This is the list of hamming loss for 50 iterations: [0.2548065786425759, 0.24836692147324532, 0.2138522121843873, 0.24183460736622656, 0.23998146861246236, 0.29279592309474173, 0.164605049803104, 0.23595089182302525, 0.17248088950660181, 0.21843873059995367, 0.26050498031040076, 0.21806810284920083, 0.25406532314107017, 0.2235348621728052, 0.2976140838545286, 0.19874913134120917, 0.25466759323604354, 0.2952050034746352, 0.21746583275422748, 0.22802872365068336, 0.27713690062543433, 0.240259439425527, 0.2500347463516331, 0.2531850822330322, 0.19962937224924715, 0.2443826731526523, 0.25304609682649987, 0.29779939772990505, 0.2824183460736623, 0.22094046791753533, 0.21704887653463054, 0.26828816307621034, 0.2432707899003938, 0.28251100301135046, 0.20060227009497336, 0.2818160759786889, 0.19898077368542968, 0.24285383368079685, 0.2549455640491082, 0.2968728283530229, 0.29877229557563123, 0.2668983090108872, 0.2521195274496178, 0.20115821172110263, 0.23710910354412787, 0.2225156358582349, 0.2834839008570767, 0.2622654621264767, 0.19805420430854762, 0.2630067176279824]\n"
     ]
    }
   ],
   "source": [
    "print('This is the list of hamming distance for 50 iterations: '+str(hamming_distance_list))\n",
    "print('This is the list of hamming score for 50 iterations: '+str(hamming_score_list))\n",
    "print('This is the list of hamming loss for 50 iterations: '+str(hamming_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of hamming distance = 5276.42\n",
      "The standard deviation of hamming distance = 717.1761593918192\n",
      "The mean of hamming distance = 0.7555515404215891\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n",
      "The mean of hamming distance = 0.24444845957841094\n",
      "The standard deviation of hamming distance = 0.03322567335611856\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "hd_mean = statistics.mean(hamming_distance_list)\n",
    "hd_std = statistics.pstdev(hamming_distance_list) \n",
    "print('The mean of hamming distance = '+str(hd_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hd_std))\n",
    "\n",
    "hs_mean = statistics.mean(hamming_score_list)\n",
    "hs_std = statistics.pstdev(hamming_score_list) \n",
    "print('The mean of hamming distance = '+str(hs_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hs_std))\n",
    "\n",
    "hl_mean = statistics.mean(hamming_loss_list)\n",
    "hl_std = statistics.pstdev(hamming_loss_list) \n",
    "print('The mean of hamming distance = '+str(hl_mean))\n",
    "print('The standard deviation of hamming distance = '+str(hl_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ISLR 10.7.2<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can check the notebook folder if the picture did not show successfully.\n"
     ]
    }
   ],
   "source": [
    "print('You can check the notebook folder if the picture did not show successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(a)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(b)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(c)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1 and 2 are in cluster 1 and observations 3 and 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(d)<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.\n"
     ]
    }
   ],
   "source": [
    "print('Observations 1, 2 and 3 are in cluster 1 and observation 4 in cluster 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>(e)<h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_e.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
