{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "import math\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import variation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from statistics import mean\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def convert_label(s):\n",
    "    if s=='neg':\n",
    "        return 0;\n",
    "    elif s=='pos':\n",
    "        return 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------part b)----------------------------------\n",
    "l1 = list(range(0,20))\n",
    "\n",
    "# read train data\n",
    "train_df_raw = pd.read_csv('../data/aps_failure_training_set.csv',\n",
    "                na_values='na',\n",
    "                index_col=None,\n",
    "                skiprows=l1)\n",
    "all_columns_list = list(train_df_raw.columns)\n",
    "\n",
    "# read test data\n",
    "test_df_raw = pd.read_csv('../data/aps_failure_test_set.csv',\n",
    "                na_values='na',\n",
    "                index_col=None,\n",
    "                skiprows=l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean,mode and knn value can be fitted in to missing values. I use mean in this case.\n"
     ]
    }
   ],
   "source": [
    "#  i)\n",
    "from sklearn.impute import SimpleImputer\n",
    "print('Mean,mode and knn value can be fitted in to missing values. I use mean in this case.')\n",
    "\n",
    "# train\n",
    "train_features_df_raw = train_df_raw.iloc[:, 1:]\n",
    "test_features_df_raw = test_df_raw.iloc[:, 1:]\n",
    "whole_features_df_raw = pd.concat([train_features_df_raw,test_features_df_raw])\n",
    "whole_df_raw = pd.concat([train_df_raw,test_df_raw])\n",
    "train_size = train_features_df_raw.iloc[:,0].size\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(whole_features_df_raw)\n",
    "x = imputer.transform(whole_features_df_raw)\n",
    "whole_features_df = pd.DataFrame(x)\n",
    "train_features_df = whole_features_df.head(train_size)\n",
    "test_features_df = whole_features_df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii)\n",
    "cv = variation(a=whole_features_df, axis = 0,nan_policy='omit')\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iii)\n",
    "whole_features_df.columns = all_columns_list[1:]\n",
    "x = whole_features_df.corr()\n",
    "seaborn.set(rc={'figure.figsize':(17,17)})\n",
    "ax = seaborn.heatmap(x,vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_feature = 13\n",
    "indices = list(np.argsort(cv)[-13:])\n",
    "df_draw = whole_features_df.iloc[:,indices]\n",
    "indices_move = [x+1 for x in indices]\n",
    "temp =[]\n",
    "for i in indices_move:\n",
    "    temp.append(all_columns_list[i])\n",
    "df_draw.columns = temp\n",
    "temp = list(whole_df_raw['class'])\n",
    "temp\n",
    "df_draw['class'] = temp\n",
    "#whole_df_raw\n",
    "df_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv)\n",
    "# floor(sqrt(170))=13\n",
    "number_of_feature = 13\n",
    "indices = list(np.argsort(cv)[-13:])\n",
    "df_draw = whole_features_df.iloc[:,indices]\n",
    "indices_move = [x+1 for x in indices]\n",
    "temp =[]\n",
    "for i in indices_move:\n",
    "    temp.append(all_columns_list[i])\n",
    "df_draw.columns = temp\n",
    "df_draw['class'] = list(whole_df_raw['class'])\n",
    "df_draw['label'] = df_draw['class'].apply(convert_label)\n",
    "df_draw = df_draw.drop('class', 1)\n",
    "df_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(df_draw,hue='label')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12), (ax13, ax14, ax15)) = plt.subplots(5, 3)\n",
    "temp = list(df_draw.columns)\n",
    "seaborn.boxplot(x = 'label', y = temp[0], data = df_draw,ax = ax1) \n",
    "seaborn.boxplot(x = 'label', y = temp[1], data = df_draw,ax = ax2) \n",
    "seaborn.boxplot(x = 'label', y = temp[2], data = df_draw,ax = ax3) \n",
    "seaborn.boxplot(x = 'label', y = temp[3], data = df_draw,ax = ax4) \n",
    "seaborn.boxplot(x = 'label', y = temp[4], data = df_draw,ax = ax5) \n",
    "seaborn.boxplot(x = 'label', y = temp[5], data = df_draw,ax = ax6) \n",
    "seaborn.boxplot(x = 'label', y = temp[6], data = df_draw,ax = ax7) \n",
    "seaborn.boxplot(x = 'label', y = temp[7], data = df_draw,ax = ax8) \n",
    "seaborn.boxplot(x = 'label', y = temp[8], data = df_draw,ax = ax9) \n",
    "seaborn.boxplot(x = 'label', y = temp[9], data = df_draw,ax = ax10) \n",
    "seaborn.boxplot(x = 'label', y = temp[10], data = df_draw,ax = ax11) \n",
    "seaborn.boxplot(x = 'label', y = temp[11], data = df_draw,ax = ax12)\n",
    "seaborn.boxplot(x = 'label', y = temp[12], data = df_draw,ax = ax13)\n",
    "#fig.tight_layout()\n",
    "fig.set_figheight(30)\n",
    "fig.set_figwidth(15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v)\n",
    "# training\n",
    "df_neg = train_df_raw[train_df_raw['class'] == 'neg']\n",
    "df_pos = train_df_raw[train_df_raw['class'] == 'pos']\n",
    "n_neg = df_neg.iloc[:,0].size\n",
    "n_pos = df_pos.iloc[:,0].size\n",
    "ratio = (n_pos/(n_pos+n_neg))*100\n",
    "print('For the train data set, there are '+str(n_neg)+' negative data and '+str(n_pos)+' positive data,')\n",
    "print('This dataset is imbalance since positive dataset is only '+str(ratio)+'% of whole dataset.')\n",
    "\n",
    "# test\n",
    "df_neg = test_df_raw[test_df_raw['class'] == 'neg']\n",
    "df_pos = test_df_raw[test_df_raw['class'] == 'pos']\n",
    "n_neg = df_neg.iloc[:,0].size\n",
    "n_pos = df_pos.iloc[:,0].size\n",
    "ratio = (n_pos/(n_pos+n_neg))*100\n",
    "print('\\nFor the test data set, there are '+str(n_neg)+' negative data and '+str(n_pos)+' positive data,')\n",
    "print('This dataset is imbalance since positive dataset is only '+str(ratio)+'% of whole dataset.')\n",
    "\n",
    "# total\n",
    "df_neg = whole_df_raw[whole_df_raw['class'] == 'neg']\n",
    "df_pos = whole_df_raw[whole_df_raw['class'] == 'pos']\n",
    "n_neg = df_neg.iloc[:,0].size\n",
    "n_pos = df_pos.iloc[:,0].size\n",
    "ratio = (n_pos/(n_pos+n_neg))*100\n",
    "print('\\nFor the whole data set, there are '+str(n_neg)+' negative data and '+str(n_pos)+' positive data,')\n",
    "print('This dataset is imbalance since positive dataset is only '+str(ratio)+'% of whole dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "# train_target\n",
    "# test_data\n",
    "# test_target\n",
    "#------------------------------part c)----------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# impute test data\n",
    "train_data = train_features_df.copy()\n",
    "train_target = train_df_raw['class'].apply(convert_label)\n",
    "test_data = test_features_df.copy()\n",
    "test_target = test_df_raw['class'].apply(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs=2\n",
    "clf = RandomForestClassifier(n_estimators=100,random_state=0,oob_score=True)\n",
    "clf.fit(train_data,train_target)\n",
    "predictions=clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix = pd.crosstab(test_target, predictions, rownames=['Actual'], colnames=['Predicted'])\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true = test_target,y_score=predictions,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "print('The area under curve is '+str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassification rate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(test_target, predictions)#.ravel()\n",
    "tn, fp, fn, tp = confusion_matrix(test_target, predictions).ravel()\n",
    "misclassification_rate = (fp+fn)/(tn+fp+fn+tp)\n",
    "print('The misclassification rate for test data is '+str(misclassification_rate))\n",
    "\n",
    "predictions=clf.predict(train_data)\n",
    "tn, fp, fn, tp = confusion_matrix(train_target, predictions).ravel()\n",
    "misclassification_rate = (fp+fn)/(tn+fp+fn+tp)\n",
    "print('The misclassification rate for training data is '+str(misclassification_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of bag error\n",
    "oob_error = 1 - clf.oob_score_\n",
    "print('The out of bag error is '+str(oob_error))\n",
    "print('The out of bag error is slightly lower than the test error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------part d)----------------------------------\n",
    "clf = RandomForestClassifier(n_estimators=100,random_state=0,oob_score=True,class_weight='balanced')\n",
    "clf.fit(train_data,train_target)\n",
    "predictions=clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(test_target, predictions, rownames=['Actual'], colnames=['Predicted'])\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true = test_target,y_score=predictions,pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "print('The area under curve is '+str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassification rate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(test_target, predictions)#.ravel()\n",
    "tn, fp, fn, tp = confusion_matrix(test_target, predictions).ravel()\n",
    "misclassification_rate = (fp+fn)/(tn+fp+fn+tp)\n",
    "print('The misclassification rate for test data is '+str(misclassification_rate))\n",
    "\n",
    "predictions=clf.predict(train_data)\n",
    "tn, fp, fn, tp = confusion_matrix(train_target, predictions).ravel()\n",
    "misclassification_rate = (fp+fn)/(tn+fp+fn+tp)\n",
    "print('The misclassification rate for training data is '+str(misclassification_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of bag error\n",
    "oob_error = 1 - clf.oob_score_\n",
    "print('The out of bag error is '+str(oob_error))\n",
    "print('The out of bag error is slightly lower than the test error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------part e)----------------------------------\n",
    "import weka.core.jvm as jvm\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "from weka.core.converters import Loader\n",
    "from weka.core.classes import Random\n",
    "from weka.core.dataset import create_instances_from_matrices\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "# train_target\n",
    "# test_data\n",
    "# test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['C:\\\\Users\\\\notya\\\\anaconda3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\rhino-1.7R4.jar', 'C:\\\\Users\\\\notya\\\\anaconda3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\runnablequeue.jar', 'C:\\\\Users\\\\notya\\\\anaconda3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\cpython.jar', 'C:\\\\Users\\\\notya\\\\anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\python-weka-wrapper.jar', 'C:\\\\Users\\\\notya\\\\anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "170",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 170 is not in range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-860daf48850f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# dataset = create_instances_from_matrices(x, y, name=\"generated from matrices\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_instances_from_matrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\weka\\core\\dataset.py\u001b[0m in \u001b[0;36mcreate_instances_from_matrices\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1699\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1700\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"N\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 170"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "jvm.start()\n",
    "x = np.random.randn(10, 5)\n",
    "y = np.random.randn(10)\n",
    "# dataset = create_instances_from_matrices(x, y, name=\"generated from matrices\")\n",
    "dataset = create_instances_from_matrices(train_data, train_target)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "dataset = create_instances_from_matrices(x, y, name=\"generated from matrices\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = Classifier(classname=\"weka.classifiers.trees.LMT\",options=['-C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------part f)----------------------------------\n",
    "from imblearn.datasets import make_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModelTree:\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def score(\"\"):\n",
    "        pass\n",
    "    \n",
    "SMOTE\n",
    "for k in range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
